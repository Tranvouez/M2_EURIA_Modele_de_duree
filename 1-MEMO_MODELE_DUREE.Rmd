---
html_document: default
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    number_sections: true
    toc_depth: 3
    latex_engine: xelatex
  header-includes:
  - \usepackage{fontspec}
  - "\\usepackage{unicode-math}"
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
always_allow_html: true
title: 'Modèles de durée : TD et Examens '
editor_options:
  markdown:
    wrap: sentence
---

\clearpage 
\newpage

```{r setup, include = FALSE, warning = FALSE, message = FALSE}
# Gestion des options sur les chunk  
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      collapse = FALSE,
                      comment = "",
                      #fig.width = 10, 
                      #fig.asp = 0.618,
                      fig.align = "center", 
                      out.width = "95%")

# Définition d'une palette de couleurs : 
palette_couleur = c("#36648B", "#F4A460", "#9AFF9A", "#FFD700", "#838B8B","#EED5B7", "#FF82AB")

```

# Les méthodes semi-paramétriques

## Le modèle de Cox

### Lecture des données traitement de la base :

```{r results='hide'}
library(tidyverse)
Re = read.table("DATA/rossi.txt", header = TRUE)
glimpse(Re)

# Suppression de la variable race : 
Re1 = Re[, -5]

```

### Etude la durée de survie selon la valeur d'une variable. (test de log-Rank)

On regarde si les fonctions de survies des individus discriminés selon les modalités d'une variable, sont significativement similaires.

On effectue pour ça le test du log-rank à l'aide de la fonction Surv du package survival.

$$
\left\{
\begin{array}{l}
H0 : \text{les fonctions de survie sont les mêmes,  p-value $\geq$ 0.05} \\
H1 : \text{les fonctions de survie sont différentes} \\
\end{array}
\right.
$$

```{r}
library(survival)
# Test sur la variable financement : 
survdiff(Surv(week, arrest) ~ fin, data = Re1)

# Surv créer un objet avec week le temps de survie et arrest l'indicateur 
# d’évènement. Fin est la variable servant à comparer les courbes. 

```

### Modélisation de Kaplan Meier :

```{r}
# Modélisation de kaplan meier, distinction sur la variable financement 
s = survfit(Surv(week, arrest) ~ fin, data = Re1)
library(ggfortify)
library(ggplot2)
autoplot(s) 
```

### Ajustement d'un modèle de Cox :

```{r}
cox1 = coxph(formula = Surv(week, arrest) ~ fin + age + wexp + mar + 
               paro + prio, data = Re1)
summary(cox1)
```

Explication du test :

$$
\left\{
\begin{array}{l}
H0 : \text{ $\beta_j$ = 0,  Pr(>|z|), prob(|U|> z), où U ~ N(0,1)} \\
H1 : \text{$beta_j \neq 0$, p-value $\leq$ 0.05} \\
\end{array}
\right.
$$ Le se(coef) correspond au sqrt(var(beta)).
On en déduit que les variables significatives sont l'âge et le prio.

### Graphique de la fonction de survie :

Dans le cadre des fonction de Kaplan Meier, Aalen par défaut les covariables sont fixées à la valeur moyenne.

```{r}
kpmr = survfit(cox1) # Fonction de survie de Kaplan-Meier pour le modèle de cox

summary(kpmr)

plot(
  kpmr,
  ylim = c(0.5, 1),
  lty = 5,
  xlab = 'Semaine',
  ylab = 'Proportion de non recidive',
  main = 'Fonction de survie estimation de Kaplan-Meier',
  col = palette_couleur[1:3], 
  lwd = 2)

legend(
  "topright",  # Position de la légende
  lty = 1,
  cex = 1,
  legend = c("KP", "lower", "upper"),
  col = palette_couleur[1:3])

```

### Fonction de hasard cumulée avec l'estimateur de Breslow :

Interprétation Intuitive:

Taux Instantané: La fonction de hasard représente le taux instantané de survenue de l'événement à un moment donné.\
Par exemple, si h(t)=0.05 à t=10 semaines, cela signifie que le taux de survenance de évènement à 10 semaines est de 5% par unité de temps.\
Conditionnelle à la Survie: La fonction de hasard est conditionnelle à la survie jusqu'à ce moment.
Elle ne prend en compte que les individus qui n'ont pas encore subi l'événement.

```{r}
plot(
  basehaz(cox1),
  main = 'Fonction de hasard de baseline',
  xlab = 'Valeur de la fonction de hasard',
  ylab = "Temsp écoulé",
  type = 'l',
  col = palette_couleur[1],
  lwd = 3
)
```

### Fonction survie pour l'individu ayant les caractéristiques du premier individu :

```{r}
# plot(survfit(cox1, newdata = Re1)) # fonction de survie pour tous les individus
# title("Fonction de survie pour tous les individus")

plot(survfit(cox1, newdata = Re1[1, ]),
     main = "Fonction de survie pour un individu donné",
     col = palette_couleur[1:3], 
     ylim = c(0.5,1), 
     lwd = 2, 
     lty = 1)
 
legend("bottomleft",
       lty = 1,
       cex = 1,
       legend = c("KP", "lower", "upper"),
       col = palette_couleur[1:3])
```

### Etude de l'effet d'une covariable (les autres étant fixées) :

Exemple : effet de la var "financement" (0 ou 1) On fixe les autres à leur valeur moyenne.

```{r}
ReFin = data.frame(
  fin = c(0, 1),
  age = rep(mean(Re1$age), 2),
  wexp = rep(mean(Re1$wexp), 2),
  mar = rep(mean(Re1$mar), 2),
  paro = rep(mean(Re1$paro), 2),
  prio = rep(mean(Re1$prio), 2)
)

plot(
  survfit(cox1, newdata = ReFin),
  lty = c(1, 2),
  ylim = c(.6, 1),
  col = palette_couleur[4:5],
  lwd = 2, 
  main = "Fonction de survie selon la modalité de financement", 
  ylab = "Probabilité de survie estimée", 
  xlab = "Période de temps écoulée"
)
legend(
  1,
  0.8,
  legend = c("fin=0", "fin=1"),
  lty = c(1, 2),
  col =  palette_couleur[4:5]
)
```

### Sélection de variable une à une :

Remarque : on peut faire de la sélection de variables en enlevant de façon itérative celles expliquant le moins (p-value la plus forte) exemple :

```{r}
cox2= coxph(formula=Surv(week,arrest)~fin+age+wexp+mar+prio,data=Re1)
summary(cox2)
```

Test hypothèse de Hasard Proportionnel : (proportionnalité des risques) $$
\left\{
\begin{array}{l}
H0 : \text{les résidus sont indépendants du temps} \\
H1 : \text{les résidus dépendent du temps} \\
\end{array}
\right.
$$

Explication : Si H0 est rejetée, alors les résidus dépendent du temps

### Test de hasard proportionnel, les résidus de Schoenfeld

```{r}
res = cox.zph(cox1)
res

# Représentation graphique
par(mfrow = c(2, 4))
plot(res)
```


# Les méthodes non-paramétriques

## La méthode de Kaplan meier :

### Génération de la base et importation des données

On créer une base de données avec des observations censurées.

```{r}
library(survival)
tempsGMP = c(rep(6, 4), 7, 9, 10, 10, 11, 13, 16, 17, 19, 20, 22, 23, 25, 32, 
             32, 34, 35) # liste des observations
finGMP = c(1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, rep(0, 5)) 
# indication des obs censurées
donnF = Surv(tempsGMP, finGMP) 
head(donnF)

```

### Ajustement d'un modèle de survie avec la méthode de Kaplan Meier :

```{r}
survKM = survfit(donnF ~ 1,
                 data = donnF,
                 type = "kaplan-meier",
                 error = "greenwood")

# Graphique de la fonction de survie moyenne : 

plot(survKM, mark.time = TRUE, col = palette_couleur[1:3])
title("Modèle de survie de Kaplan-Meier")
legend("bottomleft",  
       lty = 1,
       cex = 1,
       legend = c("KP", "lower", "upper"),
       col = palette_couleur[1:3])

# Intervalle de confiance et valeur modélisée pour l'individu 10 : 
IC_KM = round(c(survKM$lower[10], survKM$surv[10], survKM$upper[10]),4)

```

## Le modèle de Fleming-Harrington :

### Modèle de Fleming-Harrington, intervalle méthode Tsiatis :

```{r}
# Par defaut, intervalle de confiance : conf.type='log' :
survFH = survfit(donnF ~ 1,
                 data = donnF,
                 type = "fleming-harrington",
                 error = "tsiatis")

# Intervalle de confiance et valeur modélisée pour l'individu 10 : 
IC_FH = round(c(survFH$lower[10], survFH$surv[10], survFH$upper[10]),4)

```

### Modèle de Fleming-Harrington, intervalle méthode delta :

```{r}
survFHdelta = survfit(
  donnF ~ 1,
  data = donnF,
  type = "fleming-harrington",
  error = "tsiatis",
  conf.type = "plain")

IC_FHdelta = round(c(survFHdelta$lower[10], survFHdelta$surv[10], survFHdelta$upper[10]),4)

```

### Comparaison des résultats sur l'estimation du 10e individu de la base :

```{r}
#Comparaison des modèles pour le 10e individu de la base 
dt = data.frame(KM = IC_KM, FH = IC_FH, FHdelta = IC_FHdelta)
rownames(dt) = c("lower","pred","upper")
dt
```

### Représentation graphiques des trois modèles :

```{r}
# Graphiques des trois modèles : 
plot(
  survKM,
  mark.time = TRUE,
  col = palette_couleur[1],
  lwd = 2,
  xlab = "Durée de survie",
  ylab = "Probabilité de survie"
)
lines(survFH,
      mark.time = TRUE,
      col = palette_couleur[2],
      lwd = 2)
lines(survFHdelta,
      mark.time = TRUE,
      col = palette_couleur[3],
      lwd = 2)
title("Comparaison des modèles de survie")
legend(
  1,
  0.4,
  lty = 1,
  cex = 1,
  legend = c("KM", "FH", "FHdelta"),
  col = palette_couleur[1:3]
)
```


## Estimation par des lois usuelles :

### Estimation de la loi de X par une loi de Weibull :

```{r}
survweib = survreg(donnF ~ 1, dist = "weibull")
survweib
```

### Estimation de la loi de X par une loi exponentielle :

```{r}
theta = sum(finGMP) / sum(tempsGMP)
theta 

survexp = survreg(donnF ~ 1, dist = "exponential")
lambda = exp(-survexp$coefficients)
lambda

```

```{r echo=FALSE}
rm(list = setdiff(ls(), "palette_couleur")) # Nettoyage de l'environnement
```

# Examen 2018 :

## Exercice 2 :

### Importation des données et traitement de la base :

```{r}
library(StMoMo)
d = EWMaleData
De = d$Dxt # décès

ages = d$ages
annees = d$years

Ex = EWMaleData$Ext  # Expositions en milieu d'années
Lx = Ex + De / 2 # Exposition en début d'année (approximation)

# Calcul des taux de mortalité bruts pour 2011 : 
q = De[, "2011"] / Lx[, "2011"] # taux bruts

plot(
  ages,
  q,
  type = 'l',
  main = "Taux brut de mortalité",
  col = palette_couleur[1],
  lwd = 3
)
plot(
  ages,
  log(q),
  type = 'l',
  main = "Logarithme des taux bruts de mortalité",
  col = palette_couleur[1],
  lwd = 3
)

```


### Calibration d'un modèle de Makeham-Gompertz :

#### Utilisation du package fmsb :

Utilisation de la fonction fitGm pour calibrer le modèle $h(x) = C + A \times exp(\beta_x)$

Avec la fonction fitGm on peut faire le lien avec l'autre paramétrage du type :

$h(x) = \alpha + \beta \times \gamma^{x}$ où $x$ représente l'âge.


```{r}
library(fmsb)
fit = fitGM(data = q) 

A = fit[1]
B = fit[2]
C = fit[3]
cat("Modélisation fitGM :  \n")
c(A, B, C)

# Lien avec l'autre paramétrage :
alpha2 = C
beta2 = A
gamma2 = exp(B)
cat("Apha, Beta, Gamma : \n")
c(alpha2, beta2, gamma2)  

# Construction du vecteur des probabilités de décès : 
qM3 = 1 - exp(-C) * exp(-A / B * exp(B * ages) * (exp(B) - 1))

# Représentation graphique de l'âge des individus : 
plot(
  ages,
  q,
  type = 'l',
  ylab = "Probabilité de décès",
  xlab = "Ages",
  main = "Comparaison des taux de mortalités observés et estimés",
  col = palette_couleur[1],
  lwd = 2
)
lines(ages, qM3, col = palette_couleur[2], lwd = 2)
legend(
  1,
  0.3,
  lty = 1,
  cex = 1,
  legend = c("q observés", "q estimés"),
  col = palette_couleur[1:2]
)

# Comparaison des taux de mortalités logarithmiques : 

plot(
  ages,
  log(q),
  type = 'l',
  ylab = "Probabilité de décès",
  xlab = "Ages",
  main = "Comparaison des log de taux de mortalités observés et estimés",
  col = palette_couleur[1],
  lwd = 2)
lines(ages, log(qM3), col = palette_couleur[2], lwd = 2)
legend("topleft",
  lty = 1,
  cex = 1,
  legend = c("q observés", "q G-M"),
  col = palette_couleur[1:2]
)

```

Interprétation des résultats :

Le modèle de Gompertz - Makeham, avec h croissant, ne peut pas modéliser correctement la mortalité aux âges inférieurs à 20 ans.

#### Utilisation du package MortalityLaws :

```{r}
library(MortalityLaws)

#availableLaws() # Liste des modèle de mortalité du package 

fit = MortalityLaw(x = 0:100, qx = q, law = "makeham")  #modèle h(x)= C + A exp(Bx)
fit$coefficients
A = fit$coefficients["A"]
B = fit$coefficients["B"]
C = fit$coefficients["C"]
c(A, B, C)

# Lien avec l'autre paramétrage (h(x)= alpha + beta gamma^x)
alpha2 = C
beta2 = A
gamma2 = exp(B)
c(alpha2, beta2, gamma2)

# Estimation du taux de moralité de Lee-Carter 
qM4 = 1 - exp(-C) * exp(-A / B * exp(B * ages) * (exp(B) - 1))


# Représentation graphique et comparaison : 

plot(
  ages,
  log(q),
  type = 'l',
  ylab = "Probabilité de décès",
  xlab = "Ages",
  main = "Comparaison des log de taux de mortalités observés et estimés",
  col = palette_couleur[1],
  lwd = 2)
lines(ages, log(qM3), col = palette_couleur[2], lwd = 2)
lines(ages, log(qM4), col = palette_couleur[3], lwd = 2)
legend("topleft",
  lty = 1,
  cex = 1,
  legend = c("q observés", "q G-M", "q G-M bis"),
  col = palette_couleur[1:3]
)
```

### Modélisation de Lee Carter :

Rappels sur la modélisation de Lee Carter :

$ln(\mu{(x,t)}) = \alpha_x + \beta_x \times k_t + \epsilon_{(x,t)}$

Avec : \alpha\_x = la valeur moyenne

$$
\left\{
\begin{array}{l}
\alpha_x : \text{la valeur moyenne} \\
k_t : \text{correspond à une évolution générale dans le temps}
\beta_x : \text{la sensibilité du taux instantané par rapport à une variation de $k_t$} \\
\end{array}
\right.
$$

```{r}
library(forecast)
library(demography)
muh = De / Ex
Baseh = demogdata(
  data = muh,
  pop = Ex,
  ages = ages,
  years = annees,
  type = "mortality",
  label = 'G.B.',
  name = 'Hommes',
  lambda = 1) # 

lch = lca(Baseh) # Lancement du modèle de Lee-Carter

# Estimation de alpha_x
plot(lch$age, lch$ax, col = palette_couleur[1])

# Estimation de beta_x
plot(lch$age, lch$bx, col = palette_couleur[1])

# Estimation des k_t
kt = lch$kt
plot(annees, kt)

```

#### Méthode de Lee-Carter 1992 : Projection des Kt

Rappel: les Kt représentent

Hypothèse : $k_t = k_{t-1}+ d + e_t$

```{r}

# Projection des Kt à l'aide du modèle initial : 
plot(lch)
proj = forecast(lch, h = 20)
plot(proj, plot.type = "component", main = "Projection des Kt prédits")

# Projection des Kt à l'aide du modèle ARIMA : 
ar = auto.arima(kt)
plot(forecast(ar, h = 20), main = "Projection des kt prédits, Arima")

```

Interprétation (BA) :

-   $a_x$ donne une indication sur la valeur de la mortalité moyenne

-   $b_x$ la variation du taux instantané comporte trois phases.
    Le taux est de moins en moins déterminant sur les années de 0 à 20 ans ainsi que sur l'intervalle 60 à 100 ans.
    En revanche ce taux est croissant entre 20 à 60 ans.
    Ce qui correspond souvent à la période durant laquelle l'Homme est le plus actif.
    Le risque additionnel de décès à tendance à croître sur cette période.
    Enfin la période de 0 à 10 est celle qui admet un coefficient de taux instantané le plus fort du fait notamment de la mortalité infantile.

-   $k_t$ est décroissant sur toute la période, ce qui permet de conclure que la mortalité tend à décroître sur la période observée et ainsi maintient le constat d'une diminution des causes de mortalité annexes.

#### Modèle de Lee Carter sans ajustement des Kt :

Dans cette partie on fait l'hypothèse que les $k_t$ sont constants dans le temps.

```{r}
## L.C. sans ajustement des k_t
lch_sans = lca(Baseh, adjust = "none")
plot(lch$year,
     lch$kt,
     col = palette_couleur[1],
     type = 'l',
     main = "Effet de l'ajustement sur les k_t, Lee-Carter")
lines(lch_sans$year, lch_sans$kt, col = palette_couleur[2])
legend(
  1960,
  -25,
  legend = c("Avec ajust.", "Sans ajust."),
  col = palette_couleur[1:2],
  lty = 1,
  cex = 0.8
)
```

#### Comparaison des modèles :

```{r}

# Modéle de Lee Carter : 
predh = lch$fitted$y  # c'est log(mu_{x,t}) qui est prédit
mupred2011 = exp(predh[, 51])

plot(
  ages,
  q,
  type = 'l',
  ylab = "Probabilité de décès",
  xlab = "Ages",
  main = "Comparaison des probabilités de décès",
  col = palette_couleur[1],
  lwd = 2
)
lines(ages, qM3, col = palette_couleur[2], lwd = 2)
lines(ages,mupred2011,col = palette_couleur[3], lwd = 2)
legend("topleft",
  lty = 1,
  cex = 1,
  legend = c("q observés", "q G-M", "q Lee-Carter"),
  col = palette_couleur[1:3]
)


# Représentation graphique de la différence entre les modèles : 
plot(mupred2011 - qM3, 
     main = "Différence : Lee-Carter et G-M")
#max(abs(mupred2011 - qM3))

# Comparaison graphique log(q) :
plot(
  ages,
  log(q),
  type = 'l',
  ylab = "Log des probabilités de décès",
  xlab = "Ages",
  main = "Comparaison des log de taux de mortalités observés et estimés",
  col = palette_couleur[1],
  lwd = 2
)
lines(ages, log(qM3), col = palette_couleur[2], lwd = 2)
lines(ages,predh[,51],col = palette_couleur[3], lwd = 2)
lines(ages, log(qM4),col = palette_couleur[5], lwd = 2)
legend("bottomright",
  lty = 1,
  cex = 1,
  lwd = 2,
  legend = c("q observés", "q G-M", "q Lee-Carter", "q G-M MortalityLaws"),
  col = palette_couleur[c(1:3,5)]
)



```

### Calcul des rentes :

Nous souhaitons calculer la prime pure d'une rente viagère à partir de 2012 pour l'âge de 65 ans.

$a_x(t)= \sum_{k\ge 0} { \prod_{j=0}^k exp(-\mu_{x+j}(t+j)) *1/(1+r)^(k+1)}$

#### Calcul à l'aide du modèle de Lee-Carter :

```{r}

# Projections des \mu{x,t} dans le futur avec le modèle de Lee-Carter 
projh = forecast(lch, h = 70)$rate$Hommes

#dim(projh) # L'objet projh est de dimension 101 x 70 
colnames(projh) = 2012:(2012 + 69)
rownames(projh) = 0:100

r = 0.035 # valeur du taux choisi pour le facteur d'actualisation

# calcul de a_65(2012) pour les hommes :

L = length(66:101)
mu = projh[66:101, 1:L] # on limite aux âges 65-100
dmu = diag(mu)
prodexpmu = cumprod(exp(-dmu))
a = 0
for (k in 1:length(dmu))
{
  a = a + 1 / (1 + r) ^ (k) * prodexpmu[k]
}
cat("En s'arretant à 110 ans : ")
a  # 13.164

# Remarque : si on prolonge jusqu'à 120 ans avec les mêmes \mu(x,t) ?
# (pour vérifier si négliger les âges > 110 est justifié)
dmu120 = c(dmu, rep(dmu[L], 20))
prodexpmu120 = cumprod(exp(-dmu120))
a120 = 0
for (k in 1:(L + 20))
{
  a120 = a120 + 1 / (1 + r) ^ (k) * prodexpmu120[k]
}
cat("Avec la table jusque 120 ans : ")
a120 # 13.174

```

#### Calcul à l'aide du modèle de Gompertz-Makeham :

```{r}

# Comparaison avec G.M. I  (fmsb)
dmu = qM3[66:101]
prodexpmu = cumprod(exp(-dmu))
a = 0
for (k in 1:length(dmu))
{
  a = a + 1 / (1 + r) ^ (k) * prodexpmu[k]
}
cat("GM fmsb :")
a
# 12.13

# Comparaison avec G.M. II  (Mortalitylaw)
dmu = qM4[66:101]
prodexpmu = cumprod(exp(-dmu))
a = 0
for (k in 1:length(dmu))
{
  a = a + 1 / (1 + r) ^ (k) * prodexpmu[k]
}
cat("GM LawMortality : ")
a
# 12.77

```

```{r echo=FALSE}
rm(list = setdiff(ls(), "palette_couleur")) # Nettoyage de l'environnement
```

# Examen 2019 :

## Exercice 1 :

### Importation des données :

```{r}
Re = read.table(file = 'DATA/emploi.txt', header = TRUE)
str(Re)
#Re[Re$sex==2,5]=0
library(survival)
```

### Estimateur de Kaplan-Meier : test de comparaison

Rappel sur les tests :

-   Le test du log-rank et test de Gehan :

$$
\left\{
\begin{array}{l}
H0 : \text{les fonctions de survie sont les mêmes,  p-value $\geq$ 0.05} \\
H1 : \text{les fonctions de survie sont différentes} \\
\end{array}
\right.
$$

```{r}

# Test de comparaison des durées de survie selon le sexe
survdiff(Surv(tfp, des) ~ sex, data = Re, rho = 0) # log-rank
survdiff(Surv(tfp, des) ~ sex, data = Re, rho = 1) # Gehan
library(ggfortify)
s = survfit(Surv(tfp, des) ~ sex, data = Re, type = "kaplan-meier")
autoplot(s)
s

```

### Estimation par un modèle de Cox :

#### Modélisation :

Remarque :

ties=c("efron","breslow","exact") permet de choisir la méthode à adopter en cas d'événements simultanés par défaut, c'est ici l'approximation d'Efron qui est utilisée.

Ecriture du modèle de Cox :

$$
h(t) = h_0(t) \exp(\beta_1 \text{pnoj} + \beta_2 \text{edu} + \beta_3 \text{sex} + \beta_4 \text{pres} + \beta_5 \text{lfx})
$$

où : - $h(t)$ est la fonction de hasard à l'instant $t$.
- $h_0(t)$ est la fonction de hasard de base à l'instant $t$.
- $\beta_1, \beta_2, \beta_3, \beta_4, \beta_5$ sont les coefficients des covariables.
- $\text{pnoj}, \text{edu}, \text{sex}, \text{pres}, \text{lfx}$ sont les covariables incluses dans le modèle.

Analyse des résultats :

-   On teste si les coefficients sont significativement différents de 0 au seuil de 0.05%

se(coef) \<=\> sqrt(var(beta)) Test H0 : beta_j=0 ==\> Pr(\>\|z\|) : prob(\|U\|\> z), où U N(0,1)

```{r}
cox1 = coxph(formula = Surv(tfp, des) ~ pnoj + edu + sex + pres + lfx,
             data = Re)
summary(cox1)
```


#### Représentation Graphique :

```{r}
# (Kaplan Meier ou Aalen, Aalen par défaut)
# les covariables sont fixées à la valeur moyenne
summary(survfit(cox1))
plot(
  survfit(cox1),
  ylim = c(0, 1),
  xlab = 'mois',
  ylab = 'Probabilité de survie',
  main = 'Fonction de survie',
  col = palette_couleur[1:3],
  lwd = 2
)
legend(
  "topright",
  legend = c("Cox" , "lower" , "upper"),
  lwd = 2,
  col = palette_couleur[1:3]
)

# la fonction de hasard cumulée (estimateur de Breslow)
plot(basehaz(cox1),
     main = 'fonction de hasard de baseline',
     type = 'l',
     col = palette_couleur[1])

# Fonctions de survie pour des individus ayant les caractéristiques observées
#plot(survfit(cox1, newdata = Re))

# fonction de survie pour des indiv. ayant les var explicat. 
# identiques à l'ind. 1 :
#plot(survfit(cox1, newdata = Re[1,]))
```

#### Hasard proportionnel pour chaque variable :

##### Les résidus Schoenfeld :

Test hypothèse de Hasard Proportionnel le test des résidus de Schoenfeld : (proportionnalité des risques) $$
\left\{
\begin{array}{l}
H0 : \text{les résidus sont indépendants du temps} \\
H1 : \text{les résidus dépendent du temps} \\
\end{array}
\right.
$$

Explication : Si H0 est rejetée, alors les résidus dépendent du temps

Graphiquement on cherche à ne pas avoir de tendance pour attester que les résidus ne dépendent pas du temps.

```{r}

# Test hypothèse de Hasard Proportionnel :
# Résidus de Schoenfeld
res = cox.zph(cox1)
res
# Projection graphique : 
par(mfrow = c(2, 3))
plot(res)

# Remarque : 
#on ne prend en compte que les événements correspondants à des obs 
#et non des censures pour les résidus de Schoenfeld

temps = as.numeric(rownames(res$y))
length(temps)  

```

Interprétation : Les résidus de Schoenfeld nous montrent que la proportionnalité n'est pas vérifiée dans le cadre de la variable sex.
Nous pouvons réaliser un modèle stratifié sur la variable sex pour contourner le problème.

##### L'estimation linéaire : (p35 cours)

On cherche à tester la nullité du coefficient $\beta_1$ dans l'équation suivante :

$$ r_{ik}^* = \beta_0 + \beta_1 \times t_i + \epsilon_i $$

où :

\begin{itemize}
    \item $r_{ik}^*$ représente les résidus de Schoenfeld standardisé pour la $k$-ème covariable au temps $t_i$.
    \item $\beta_0$ est l'ordonnée à l'origine, représentant la valeur moyenne des résidus de Schoenfeld lorsque $t_i = 0$.
    \item $\beta_1$ est le coefficient de pente, représentant la variation des résidus de Schoenfeld en fonction du temps $t_i$.
    \item $t_i$ est le temps d'événement pour le $i$-ème individu.
    \item $\epsilon_i$ est le terme d'erreur, représentant la variabilité non expliquée par le modèle.
\end{itemize}


```{r}
### test corrélations par méthode de régression linéaire (ne marche pas ?)
# temps = Re[Re$des == 1, ]$tfp  # on ne prend pas les censures
# regpnoj = lm(res$y[, 1] ~ temps)
# summary(regpnoj)
# 
# regedu = lm(res$y[, 2] ~ temps)
# summary(regedu)
# 
# regsex = lm(res$y[, 3] ~ temps)
# summary(regsex)
# # cela ne marche pas pour la var. "sex" .
# 
# regpres = lm(res$y[, 4] ~ temps)
# summary(regpres)
# 
# reglfx = lm(res$y[, 5] ~ temps)
# summary(reglfx)
```

### Modélisation stratifiée sur la variable Sex :

On scinde la population en deux groupe puis on applique un modèle par groupe.
On rappelle que Sex 1 = Homme et Sex 2 = Femme.

```{r}
coxStrafin =  coxph(formula = Surv(tfp, des) ~ strata(sex) + pnoj + edu +
                      pres + lfx,data = Re)
summary(coxStrafin)
plot(
  survfit(coxStrafin),
  ylim = c(0, 1),
  lty = c(1, 2),
  main = 'Modèle de Cox stratifié / sexe', 
  ylab = 'Probabilité de survie', 
  xlab = "Nombre de mois",
  col = palette_couleur[1:2], 
  lwd = 2
)
legend(100,
       0.8,
       legend = c("sex=1", "sex=2"),
       lty = c(1, 2), 
       col = palette_couleur[1:2], 
       lwd = 2)

```

Interprétation modèle :

Exemple sur l'indicateur de prestige de l'emploi courant.

Une augmentation d'une unité de prestige est associée à une diminution de 2.3% du risque de fin d'emploi (p-valeur = 1.14e-05, très significatif).

#### La fonction de hasard par sexe :

```{r}
# la fonction de hasard cumulée (estimateur de Breslow)
bh = basehaz(coxStrafin)
s1 = which(bh$strata == "sex=1")
s2 = which(bh$strata == "sex=2")
plot(
  bh$time[s2],
  bh$hazard[s2],
  main = 'Fonction de hasard de baseline',
  type = 'l',
  col = palette_couleur[1],
  lwd = 2
)
lines(bh$time[s1], bh$hazard[s1], col = palette_couleur[2])
legend(
  "topleft",
  lwd = 2,
  col = palette_couleur[1:2],
  legend = c("Femme", "Homme")
)
```

#### Comparaison entre les deux modèles :

##### Résultats de projection sur les mois 100 et 200 :

```{r}
# Modèle unique pour hommes : 
indH = data.frame(
  sex = 1,
  pnoj = mean(Re$pnoj),
  edu = mean(Re$edu),
  pres = mean(Re$pres),
  lfx = mean(Re$lfx)
)
sH = survfit(cox1, newdata = indH)
m_homme = c(sH$surv[sH$time == 100], # 0.354
  sH$surv[sH$time == 200] # 0.202
  )


# Modèle unique pour hommes et femmes :
indF = data.frame(
  sex = 2,
  pnoj = mean(Re$pnoj),
  edu = mean(Re$edu),
  pres = mean(Re$pres),
  lfx = mean(Re$lfx)
)

sF = survfit(cox1, newdata = indF)
m_femme = c(
sF$surv[sF$time == 100], # 0.215
sF$surv[sF$time == 200] # 0.094
)

# Modèle stratifié pour hommes : 
sH1 = survfit(coxStrafin, newdata = indH)
mh_strat = c(
sH1$surv[sH1$time == 101], # 0.355
sH1$surv[sH1$time == 202] # 0.213
)

# Modèle stratifié pour femmes : 
sF1 = survfit(coxStrafin, newdata = indF)
mf_strat <- c(
sF1$surv[sF1$time == 100], # 0.211
sF1$surv[sF1$time == 200]  # 0.081
)

# Tableau résultats : 

tab = matrix(
  c(m_homme, m_femme, mh_strat, mf_strat),
  nrow = 2,
  byrow = TRUE)
rownames(tab) = c('Mois 100 :', 'Mois 200: ')
colnames(tab) = c('Homme', 'Femme', 'Homme-strat', 'Femme-strat')
round(tab, 3)

```

##### Représentation graphique :

```{r}
plot(
  survfit(cox1, newdata = indH)$surv,
  ylim = c(0, 1),
  xlab = 'mois',
  ylab = 'Proba survie',
  main = 'Fonction de survie', 
  col = palette_couleur[1], 
  lwd = 2, 
  type = 'l'
)

lines(
  survfit(cox1, newdata = indF)$surv,
  ylim = c(.1, 1),
  xlab = 'mois',
  ylab = 'Proba survie',
  main = 'Fonction de survie',
  col = palette_couleur[2], 
  lwd = 2
)

lines(
  survfit(coxStrafin, newdata = indH)$surv,
  ylim = c(0, 1),
  xlab = 'mois',
  ylab = 'Proba survie',
  main = 'Fonction de survie',
  col = palette_couleur[3], 
  lwd = 2
)

lines(
  survfit(coxStrafin, newdata = indF)$surv,
  ylim = c(0, 1),
  xlab = 'mois',
  ylab = 'Proba survie',
  main = 'Fonction de survie',
  col = palette_couleur[4], 
  lwd = 2)

legend(
  "topright",
  legend = c("Homme", "Femme", "Homme stratifié", "Femme stratifié"),
  col = palette_couleur[1:4],
  lty = 1,
  cex = 0.8
)

```

### Ajout de la variable Age au début de l'emploi :

```{r}
# Création de la variable : 
agedeb = Re$tstart - Re$tb
Re1 = data.frame(Re, agedeb)

# Génération du modèle :
coxStrafin1 =  coxph(
  formula = Surv(tfp, des) ~ strata(sex) + pnoj + edu + pres + lfx + agedeb,
  data = Re1
)
summary(coxStrafin1)

# Attention à la corrélation entre les variables explicatives : (BA)
# library(corrplot)
# corrplot(cor(Re1[, c("pnoj", "edu", "pres", "lfx", "agedeb")]), 
# method = "circle", diag = TRUE)


```

Interprétation des résultats :

-   On s’aperçoit que l'ajout de la variable age au début de l'emploi n'est pas significative.
-   De plus la variable Expérience sur le marché de l'emploi n'est pas significative.

```{r}
coxStrafin2 =  coxph(formula = Surv(tfp, des) ~ strata(sex) + pnoj + edu +
                       pres + agedeb,
                     data = Re1)
summary(coxStrafin2)

```

Interprétation :

-   Toutes les variables sont significatives au seuil de 5%.

##### Etude de la proportionnalité des risques :

```{r}
res = cox.zph(coxStrafin2)
res
par(mfrow = c(2, 2))
plot(res)
```

Interprétation :

-   Les résidus de Schoenfeld ne dépendent pas du temps pour les variables explicatives.

```{r echo=FALSE}
rm(list = setdiff(ls(), "palette_couleur")) # Nettoyage de l'environnement
```

# Examen 2020-2021 : 

## Exercice 1 : 

### Importation des données :


```{r}
Ex = read.csv("DATA/ExposuresJapon1.csv", header = TRUE, sep = ";")
DC = read.csv("DATA/DeathsJapon1.csv", header = TRUE, sep = ";")
ex = Ex
de = DC
annee = unique(de$Year)
nc = length(annee)
age = unique(de$Age)
nl = length(age)
```


### Calibration de Lee-Carter sur la base Femme : 

```{r}
library(forecast)
library(demography)

muf = matrix(de$Female / ex$Female, nl, nc)  # Données Femmes
muh = matrix(de$Male / ex$Male, nl, nc)  # H

popf = matrix(ex$Female, nl, nc)
poph = matrix(ex$Male, nl, nc)

Baseh = demogdata(
  data = muh,
  pop = poph,
  ages = age,
  years = annee,
  type = "mortality",
  label = 'France',
  name = 'Hommes',
  lambda = 1
)

Basef = demogdata(
  data = muf,
  pop = popf,
  ages = age,
  years = annee,
  type = "mortality",
  label = 'France',
  name = 'Femmes',
  lambda = 1
)

# Estimation sur la base femme : 
lcf = lca(Basef)

```

#### Affichage des coefficients estimés : 

```{r}
# Estimation de alpha_x
plot(
  lcf$age,
  lcf$ax,
  col = palette_couleur[1],
  main = "Estimation de alpha_x",
  type = 'l',
  lwd =  2
)

# Estimation de beta_x
plot(
  lcf$age,
  lcf$bx,
  col = palette_couleur[2],
  main = "Estimation de beta_x",
  type = 'l',
  lwd =  2
)

# Estimation de kt : 
kt = lcf$kt

plot(
  annee,
  kt,
  main = "Estimation de kt",
  col = palette_couleur[3],
  type = 'l',
  lwd =  2
)

```

#### Projection des Kt : 

On peut projeter avec la méthode forecast ou avec une modélisation autorégressive. 

```{r}
plot(lcf)
proj = forecast(lcf, h = 20)
plot(proj, plot.type = "component", main = "Projection des Kt prédits")

```

```{r}
ar = auto.arima(kt)
plot(forecast(ar, h = 20))

```


### Modélisation sans ajustement des KT : 

```{r}
lcf_sans = lca(Basef, adjust = "none")
plot(lcf$year,
     lcf$kt,
     col = palette_couleur[1],
     type = 'l',
     main = "Effet de l'ajustement sur les k_t, Lee-Carter", 
     ylab = "kt", 
     xlab = "Année", 
     lwd = 2)
lines(lcf_sans$year, lcf_sans$kt, col = palette_couleur[2], lwd = 2)
legend('topright',
  legend = c("Avec ajust.", "Sans ajust."),
  col = palette_couleur[1:2],
  lty = 1,
  cex = 0.8, 
  lwd = 2
)

```


## Exercice 2 : 

### Importation des données : 

```{r}
Ex = read.csv("DATA/ExposuresJapon1.csv", header = TRUE, sep = ";")
DC = read.csv("DATA/DeathsJapon1.csv", header = TRUE, sep = ";")
ex = Ex
de = DC
annee = unique(de$Year)
nc = length(annee)
age = unique(de$Age)
nl = length(age)
```

### Question 1 : Calibration de Lee-Carter 

#### Modélisation sur la base Femme : 

```{r}
library(forecast)
library(demography)

ind = which((de$Age > 29) & (de$Age < 101) & (de$Year < 2011))

annee = 1947:2010
nc = length(annee)
age = 30:100
nl = length(age)

muf = matrix(de$Female[ind] / ex$Female[ind], nl, nc)
muh = matrix(de$Male[ind] / ex$Male[ind], nl, nc)
mui = matrix(de$Total[ind] / ex$Total[ind], nl, nc)

popf = matrix(ex$Female[ind], nl, nc)
poph = matrix(ex$Male[ind], nl, nc)
popi = matrix(ex$Total[ind], nl, nc)

Baseh = demogdata(
  data = muh,
  pop = poph,
  ages = age,
  years = annee,
  type = "mortality",
  label = 'France',
  name = 'Hommes',
  lambda = 1
)
Basef = demogdata(
  data = muf,
  pop = popf,
  ages = age,
  years = annee,
  type = "mortality",
  label = 'France',
  name = 'Femmes',
  lambda = 1
)
Basei = demogdata(
  data = mui,
  pop = popi,
  ages = age,
  years = annee,
  type = "mortality",
  label = 'France',
  name = 'Individus',
  lambda = 1
)

lch = lca(Baseh)
lcf = lca(Basef)
lci = lca(Basei)

predh = lch$fitted$y
predf = lcf$fitted$y  # c'est log(mu_{x,t})
predi = lci$fitted$y

# RMSE sur période calibration (idem précédemment)
rmsef = sqrt(sum((log(muf) - (predf)) ^ 2) / nl / nc)
rmseh = sqrt(sum((log(muh) - (predh)) ^ 2) / nl / nc)
rmsei = sqrt(sum((log(mui) - (predi)) ^ 2) / nl / nc)
c(rmsef, rmseh, rmsei)

```

#### Projection du modèle de Lee-Carter :

On projette de 2011 à 2017 avec la méthode forecast.

```{r}
projh = forecast(lch, h = 7)$rate$Hommes
projf = forecast(lcf, h = 7)$rate$Femmes
proji = forecast(lci, h = 7)$rate$Individus

# On peut le calculer d'une autre manière : 

kp = forecast(lcf, h = 7)$kt.f$mean[7] + lcf$kt[length(lcf$kt)]
pf = exp(lcf$ax + lcf$bx * kp)

```

Commentaire sur la deuxième méthode : 

forecast(lcf,h=7)$kt.f$ mean renvoie les delta kt d'une marche aléatoire avec drift il faut ajouter la valeur du dernier kt avant projection. 



#### Calcul du RMSE de prédiction : 

```{r}
ind = which((de$Age > 29) & (de$Age < 101) & (de$Year >= 2011))
annee = 2011:2017
nc = length(annee)

muf = matrix(de$Female[ind] / ex$Female[ind], nl, nc)
muh = matrix(de$Male[ind] / ex$Male[ind], nl, nc)
mui = matrix(de$Total[ind] / ex$Total[ind], nl, nc)
rmsef = sqrt(sum((log(muf) - log(projf)) ^ 2) / nl / nc)
rmseh = sqrt(sum((log(muh) - log(projh)) ^ 2) / nl / nc)
rmsei = sqrt(sum((log(mui) - log(proji)) ^ 2) / nl / nc)
E1 = c(rmsef, rmseh, rmsei)
E1
```

#### Représentation graphique des log(mu et obs, 2017)

```{r}
plot(
  30:100,
  muf[,7],
  col = palette_couleur[1],
  type = 'l',
  main = "Projection de log(mu) et obs, 2017",
  ylab = "log(mu)",
  xlab = "Année",
  lwd = 2
)
lines(30:100, projf[,7], col = palette_couleur[2], lwd = 2)
legend(
  "topleft",
  legend = c("Obs", "LC Proj"),
  col = palette_couleur[1:2],
  lty = 1,
  cex = 0.8,
  lwd = 2
)

```

#### Comparaison des q_obs(x=90,2017) et mu(x=90,2017) : 

```{r}
colnames(muf)= annee
rownames(muf)= age
idx = which(rownames(muf)==90) #Récupération de l'âge 90

dt = data.frame(calcul_main_kt = pf[idx], 
                estimé = projf[idx,7],
                observé = muf[idx,7])
dt
```

### Question 2 : Modélisation log-Linéaire 

#### Calibration de modèle pour les femmes : 

```{r}
ind = which((de$Age > 29) & (de$Age < 101) & (de$Year < 2011))
annee = 1947:2010
nc = length(annee)
age = 30:100
nl = length(age)

muf1 = matrix(de$Female[ind] / ex$Female[ind], nl, nc)

al = rep(0, nl)
be = rep(0, nl)

lg = log(muf1/(1-muf1))

# On utilise la fonction lm pour chaque âges : 
for (i in 1:nl)
{
  reg = lm(lg[i, ] ~ annee)
  be[i] = reg$coefficients[2]
  al[i] = reg$coefficients[1]
}

# Autres méthodes possibles : 

# al2 = rep(0, nl)
# be2 = rep(0, nl)
# mt = mean(annee)
# mt2 = mean(annee ^ 2)
# deno = mt2 - mt ^ 2
# for (i in 1:nl)
# {
#   be2[i] = (sum(annee * lg[i, ]) / nc - mt / nc * sum(lg[i, ])) / deno
#   al2[i] = 1 / nc * sum(lg[i, ]) - be2[i] * mt
# }

# Prédiction sur les années 1947- 2010 : 
# lgpred = lg
# for (i in 1:nl)
# {
#   for (j in 1:nc)
#   {
#     lgpred[i, j] = al[i] + be[i] * annee[nc]
#   }
# }
# 
# # on en déduit les q(x,t) =exp(lg(x,t))/(1+exp(lg(x,t)))
# qpred = exp(lgpred) / (1 + exp(lgpred))
# dim(qpred)

```

#### Prédiction sur les années 2011-2017 : 

```{r}
# Prédiction pour les femmes 2011-2017 : 
npa = 7 

lgpred = matrix(0, nl, npa)
an = 2011:2017
for (i in 1:nl)
{
  for (j in 1:npa)
  {
    lgpred[i, j] = al[i] + be[i] * an[j]
  }
}

qpred = exp(lgpred) / (1 + exp(lgpred))
dim(qpred)
```
#### Représentation graphiques de l'estimation et de l'observé  : 

```{r}
plot(x = age, 
     y = muf[,7],
     main = "Projection de qx estm et qx obs, 2017",
     xlab = "Age",
     ylab = "log(mu)",
     type = "l",
     col = palette_couleur[1],
     lwd = 2
     )
lines(x = age, 
      y = qpred[,7],
      col = palette_couleur[2],
      lwd = 2
      )
legend("topleft",
       legend = c("Obs", "Proj"),
       col = palette_couleur[1:2],
       lty = 1,
       cex = 0.8,
       lwd = 2
       )
```

#### Comparaison des coefficients : 

```{r}
idx = which(rownames(muf) == 90)
dt = round(data.frame(q_obs = muf[idx,7], 
                LC_estim = projf[idx,7], 
                Log_lin_estim = qpred[idx,7]),6)
dt
```

#### Calcul du RMSE projection log_lin : 


```{r}
npa = 7 
nl = length(age)
E2 = sqrt(sum((log(muf)-log(qpred))^2)/nl/npa)
E2
```

### Comparaion du modèle question 1 et question 2 : 

```{r}
dt = round(data.frame(err_m1 = E1[1], 
                err_mod2 = E2),5)
rownames(dt) = c("Mod F")
dt
```


```{r echo=FALSE}
rm(list = setdiff(ls(), "palette_couleur")) # Nettoyage de l'environnement
```

# Examen 2022-2023 : 

Examen de Mars 2023. Données Veteran. L’objectif est d’étudier les relations entre le temps de survie pour les patients atteints du cancer des poumons et les variables explicatives trt, celltype , karno , age et prior.

## Exercice 1 : 

### Remplacer la variable prior par une variable binaire : 

```{r}
library(survival)
x = veteran 
x$prior = 1*(x$prior == 10)
levels(x$prior) = c("Non", "Oui")

```


### Test de comparaison des durées

```{r}
survdiff(Surv(time,status)~celltype,data=x)
library(ggfortify)
s = survfit(Surv(time,status)~celltype,data = x,type = "kaplan-meier")
autoplot(s)
s
```


La p-value est très petite, la différence entre les lois de survie selon celltype est donc significative.


### Test de comparaison des durées de survie selon le traitement. 

```{r}
survdiff(Surv(time,status)~trt,data=x)
s = survfit(Surv(time,status)~trt,data = x,type = "kaplan-meier")
autoplot(s)
s
```

La p-value est grande, la différence entre les lois de survie selon le traitement n'est donc pas significative.

### Modélisation de Cox (variables explicatives): 

#### Sélection des variables explicatives : 

```{r}
cox0 = coxph(
  formula = Surv(time, status) ~ trt + celltype + karno + age + prior + 
    diagtime,
  data = x
)
summary(cox0)
```

Dans le summary, les hypothèses $H_0 : \beta_j=0$ sont testées.  Les quantités $Pr(>|z|)$ sont $P(|U|> z)$, avec $U$ de loi normale ${\cal N}(0,1)$.
La quantité $se(coef)$ est  l'écart-type de l'estimateur de $\beta_j$.

On peut calibrer des modèles plus simples en retirant les variables les moins significatives.

```{r}
cox1 = coxph(formula = Surv(time, status) ~ trt + celltype + karno + age + prior, data = x)
summary(cox1)

# Sélection des variables explicatives : 

cox2 = coxph(formula=Surv(time,status)~trt+celltype+karno+age,data=x)
#summary(cox2)

cox3 = coxph(formula=Surv(time,status)~trt+celltype+karno,data=x)
#summary(cox3)

```

Nous pouvons tracer le graphe de la fonction de survie (Kaplan Meier ou Aalen, c'est Aalen par défaut).
Les covariables sont fixées à leur valeur moyenne.


#### Affichage graphique du modèle à sept variables : 

```{r}
summary(survfit(cox1))
plot(
  survfit(cox1),
  ylim = c(.1, 1),
  xlab = 'mois',
  ylab = 'Proba survie',
  main = 'Fonction de survie', 
  col = palette_couleur[1:3], 
  lwd = 2
)
legend(
  "topright",
  legend = c('Proba survie', "lower", "upper"),
  col = palette_couleur[1:3],
  lty = 1,
  cex = 0.8, 
  lwd = 2
)

```

#### Fonction de hasard du modèle à 7 paramètres : 

Nous pouvons tracer la fonction de hasard cumulée (estimateur de Breslow).

```{r}
plot(
  basehaz(cox1),
  main = 'fonction de hasard de baseline',
  xlab = 'temps',
  ylab = 'hazard',
  type = 'l',
  col = palette_couleur[1],
  lwd = 2
)
```


#### Fonction de survie des individus observés : 

Nous pouvons tracer les fonctions de survie pour des individus ayant les caractéristiques observées.
```{r}
plot(survfit(cox1,newdata=veteran), 
     main = 'Fonction de survie des individus observés',
     xlab = 'Temps',
     ylab = 'Proba survie',
     lwd = 2)
```
Ou la fonction de survie pour des individus ayant les var explicatives identiques à l'individu 1 par exemple.

#### Représentation graphique du premier individu : 

```{r}
tcox1 = survfit(cox1, newdata = veteran[1, ])

plot(tcox1, 
     main = "Fonction de survie de l'individu 1", 
     xlab = "Temps",
     ylab = "Proba survie",
     lwd = 2 , 
     col = palette_couleur[1:3])
legend("topright",
  legend = c('Proba survie', "lower", "upper"),
  col = palette_couleur[1:3],
  lty = 1,
  cex = 0.8, 
  lwd = 2) 
```

#### Test de proportionnalité des résidus : 
 
On test l'hypothèse de Hasard Proportionnel, avec les résidus de Schoenfeld.
 
```{r}
res = cox.zph(cox1)
res
par(mfrow = c(3, 3))
plot(res)
```

Les variables celltype, karno et Global ne respectent pas l'hypothèse de proportionnalité. 


## Exercice 2 :Forêt aléatoire de survie : package randomForestSRC

Voir : 

[Référence1](https://www.randomforestsrc.org/articles/getstarted.html)

[Référence2](https://www.randomforestsrc.org/articles/survival.html)

[Référence3](https://www.randomforestsrc.org/reference/rfsrc.html)

[Référence4](https://www.randomforestsrc.org/cheatsheets.pdf)

### Importation des données et modélisation :

```{r}
library(randomForestSRC)
data(veteran, package = "randomForestSRC")
v.obj <- rfsrc(Surv(time, status) ~ ., data = veteran, 
                   ntree = 100)

## plot tree number 3
plot(get.tree(v.obj, 3))
```

#### Résultats de l'apprentissage :

```{r}
print(v.obj)
```

##### Affichage du C-index du modèle : 

```{r}
get.cindex(
  time = veteran$time,
  censoring = veteran$status,
  predicted = v.obj$predicted.oob
)
```
Explication du C-index : 

Le C-index est une mesure de la qualité du modèle de forêt aléatoire, plus est élevé meilleur est le modèle. 

#### Graphique de la fonction de survie pour les 10 premiers individus :


```{r}
matplot(
  v.obj$time.interest,
  t(v.obj$survival.oob[1:10,]),
  xlab = "Time",
  ylab = "Survival",
  type = "l",
  lty = 1
)
```



#### Synthèse des résultats : 


La fonction plot survival permet d'avoir une synthèse graphique de résultats :  

```{r}
plot.survival(v.obj, subset = 1)
```


#### Performances du modèle RSF :

```{r}
## obtain Brier score using KM and RSF censoring distribution estimators
bs.km <- get.brier.survival(v.obj, cens.model = "km")$brier.score
bs.rsf <- get.brier.survival(v.obj, cens.model = "rfsrc")$brier.score

# plot the brier score
 plot(bs.km, type = "s", col = 2)
 lines(bs.rsf, type ="s", col = 4)
 legend("topright", legend = c("cens.model = km", "cens.model = rfsrc"), fill = c(2,4))
```


### Importance des variables (VIMP) :

(Problème sur les sorties pdf mais sortent en local)

Plusieurs méthodes sont possibles pour l'importance d'une variable $x$ : 
  
  - importance = "permute" : calcul d'importance par permutation aléatoire des valeurs de $x$ observées sur les exemples OOB.

- importance = "random" : calcul d'importance par choix aléatoire gauche droite lorsqu'une coupure se fait avec la variable $x$.

- importance = "anti" : calcul d'importance en choisissant le choix opposé à celui proposé.
  
```{r}
# imp1 = subsample(v.obj, importance = "anti")
# plot(imp1)
```

  
```{r}
  # imp2 = subsample(v.obj, importance = "permute")
  # plot(imp2)
```
  
  
```{r}
  # imp3 = subsample(v.obj, importance = "random")
  # plot(imp3)
```
  
### Comparaison de modèle entre Cox et forêt aléatoire de survie : 
  
  Comparaison des fonctions de survie entre une forêt aléatoire de survie et le modèle de Cox, pour l'individu 1:

```{r}
plot(
  v.obj$time.interest,
  t(v.obj$survival.oob[1, ]),
  xlab = "Time",
  ylab = "Survival",
  type = "l",
  lty = 1,
  col = palette_couleur[1],
  lwd = 2
)
lines(tcox1$time, tcox1$surv, col = palette_couleur[2],
      lwd = 2)
legend(
  "topright",
  col = palette_couleur[1:2],
  legend = c("Forêt aléatoire", "Cox"),
  lty = 1,
  cex = 0.8,
  lwd = 2
)

```

```{r echo=FALSE}
rm(list = setdiff(ls(), "palette_couleur")) # Nettoyage de l'environnement
```

# Examen 2023-2024 :

Examen de Janvier 2024.
Données PBC (Primary Biliary Cirrhosis).
L’objectif est d’étudier le temps de survie pour les patients atteints de cirrhose biliaire primitive.
La cirrhose biliaire primitive est une maladie chronique du foie rare mais mortelle, de cause inconnue, avec une prévalence d'environ 50 cas par million d'habitants.
L'événement pathologique primaire semble être la destruction des canaux biliaires interlobulaires, qui peut être médiée par des mécanismes immunologiques.
Entre janvier 1974 et mai 1984, la Mayo Clinic a mené un essai randomisé en double aveugle sur la cirrhose biliaire primitive du foie (CBP), comparant le médicament D-pénicillamine (DPCA) à un placebo.
Quatre cent vingt-quatre patients répondant aux critères d'éligibilité ont été vus à la clinique pendant la période d'inscription à l'essai.
Le médecin traitant et le patient ont accepté de participer à l'essai randomisé dans 312 des 424 cas.
La date de la randomisation et un grand nombre de paramètres cliniques, biochimiques, sérologiques et histologiques ont été enregistrés pour chacun des 312 patients de l'essai clinique.
Les données de l'essai ont été analysées en 1986 pour être présentées dans la littérature clinique.
Pour cette analyse, l'état de la maladie et de la survie en juillet 1986 a été enregistré pour le plus grand nombre possible de patients.
À cette date, 125 des 312 patients étaient décédés, dont 11 seulement n'étaient pas attribuables à la CBP.
Huit patients avaient été perdus de vue et 19 avaient subi une transplantation hépatique.

## Importation des données et suppression des variables avec valeurs manquantes :

```{r}
library(randomForestSRC)
library(survival)
data(pbc, package = "randomForestSRC")
x = pbc[1:312, ]
p = dim(x)[2]
E = c()

for (i in 1:p)
{
  if (sum(is.na(x[, i])) > 0)
  {
    E = c(E, i)
  }
}
x = x[, -E] # On a enlevé les variables avec valeurs manquantes (NA)

cat("Dimension de la base de données : \n")
dim(x)
```

## Estimation de Kaplan Meier simple :

```{r}
library(ggfortify)
s = survfit(Surv(days, status) ~ 1, data = x, type = "kaplan-meier")
autoplot(s)

```

## Test de comparaison de survie selon le traitement :

```{r}
survdiff(Surv(days,status)~treatment,data=x)
s = survfit(Surv(days,status)~treatment,data = x,type = "kaplan-meier")
autoplot(s)
s
```

Commentaire analyse (mistral ai) :

Traitement 1 : - 158 sujets ont été suivis.
- 65 événements ont été observés.
- Le temps médian de survie est de 3282 jours.
- L'intervalle de confiance à 95% pour le temps médian de survie est [2583, NA], ce qui signifie que la limite supérieure n'est pas définie, probablement parce que plus de la moitié des sujets n'ont pas encore eu d'événement.

Commentaire (Prof) :

La p-value est élevée, la différence entre les lois de survie selon le traitemnet n'est donc pas significative.
Au seuil de 5% la fonction de survie ne change pas selon le type d'évenement.

## Modélisation de Kaplan-Meier en distinguant le sexe des individus :

```{r}
survdiff(Surv(days,status)~sex,data=x)
library(ggfortify)
s = survfit(Surv(days,status)~sex,data = x,type = "kaplan-meier")
autoplot(s)
s
```

Commentaire (prof) :

La p-value est de 0.04, la différence entre les lois de survie selon le sexe est donc significative au niveau de rejet 0.05.

## Expliquer la durée de survie par des variables (modèle de Cox) :

Remarque :

ties=c("efron","breslow","exact") permet de choisir la méthode à adopter en cas d'événements simultanés Par défaut, c'est ici l'approximation d'Efron qui est utilisée.

### Calibration du modèle :

```{r}

cox0= coxph(formula=Surv(days,status)~.,data=x)
summary(cox0)

```

Commentaire :

Dans le summary, les hypothèses $H_0 : \beta_j=0$ sont testées.
Les quantités $Pr(>|z|)$ sont $P(|U|> z)$, avec $U$ de loi normale \$ N(0,1)\$.
La quantité $se(coef)$ est l'écart-type de l'estimateur de $\beta_j$.

### Probabilité de survie au moins 400 jours pour individu 1 :

```{r}
tcox0 = survfit(cox0, newdata = x[1, ])
i = which(tcox0$time == 400)
tcox0$surv[i]
```

## Simplification du modèle avec 7 variables explicatives :

### Calibration modèle :

On peut calibrer des modèles plus simples en retirant les variables les moins significatives.

```{r}
cox1 = coxph(
  formula = Surv(days, status) ~ age + edema + bili + albumin + 
    sgot + prothrombin + stage,
  data = x
)
summary(cox1)
```

#### Graphique fonction de survie :

Nous pouvons tracer le graphe de la fonction de survie (Kaplan Meier ou Aalen, c'est Aalen par défaut).
Les covariables sont fixées à leur valeur moyenne.

```{r}
#summary(survfit(cox1)) # Affichage des probabilités de survie
plot(
  survfit(cox1),
  ylim = c(.1, 1),
  xlab = 'Mois',
  ylab = 'Proba survie',
  main = 'Fonction de survie de Kaplan-Meier',
  col = palette_couleur[1:3], 
  lwd = 2
)
legend(
  "bottomleft",
  legend = c("Cox" , "lower" , "upper"),
  lwd = 2,
  col = palette_couleur[1:3], 
)

```

#### Fonction de hasard :

```{r results='hide'}
# Nous pouvons tracer la fonction de hasard cumulée 
# (estimateur de Breslow).

plot(basehaz(cox1), main = 'fonction de hasard de baseline', type = 'l')
```

#### Fonction de survie des individus observés :

```{r results='hide'}
#plot(survfit(cox1,newdata=x))

```

### Vérification de l'hypothèse de proportionnalité du modèle :

```{r}
res=cox.zph(cox1)
res
#par(mfrow=c(3,3))
#plot(res)
```

Interprétation :

-   Les résidus de la variables bili ne sont pas indépendants du temps.
-   Il faut relancer le modèle en stratifiant sur la variable bili.

### Probabilité de survie 400 jours premier individus de la base :

```{r}
# Ou la fonction de survie pour des individus ayant les var 
# explicatives identiques à l'individu 1 par exemple.
#plot(survfit(cox1,newdata=x[1,]))
tcox1=survfit(cox1,newdata=x[1,])
i=which(tcox1$time==400)
#i
tcox1$surv[i]
```

## Modélisation Forêt aléatoire de survie :

### Calibration du modèle

```{r}
library(randomForestSRC)
v.obj <- rfsrc(Surv(days,status)~., data = x, 
                   ntree = 100)

## plot tree number 3
plot(get.tree(v.obj, 3))
```

### Récupération du C-index :

```{r}
get.cindex(time=x$days,censoring=x$status,predicted=v.obj$predicted.oob)
```

Interprétation du C-index :

-   Le C-index est de 0.16 ainsi le modèle de forêt aléatoire prédit très mal la mortalité.

#### Graphique de la fonction de survie :

```{r}
#Le graphe de la fonction de survie pour les 10 premiers individus :

matplot(v.obj$time.interest,  t(v.obj$survival.oob[1:10, ]),
    xlab = "Time", ylab = "Survival", type = "l", lty = 1)
```

### Comparaison des modèles Cox et Forêt aléatoire pour l'individu 1 :

Comparaison des fonctions de survie entre une forêt aléatoire de survie et le modèle de Cox, pour l'individu 1:

```{r}
plot(
  v.obj$time.interest,
  t(v.obj$survival.oob[1,]),
  xlab = "Temps",
  ylab = "Probabilté de survie",
  main = "Comparaison des modèles de survie",
  type = "l",
  lty = 1,
  col = palette_couleur[1],
  lwd = 2
)
lines(tcox1$time, tcox1$surv, col = palette_couleur[2], lwd = 2)
lines(tcox0$time, tcox0$surv, col = palette_couleur[3], lwd = 2)
legend(
  "topright",
  legend = c("Random Forest", "Cox 7 var", "Cox All var"),
  fill = palette_couleur[1:3]
)

# Prédiction de la mortalité au 400e jour pour l'individu 1 : 
i=which(v.obj$time.interest==400)
i
v.obj$survival.oob[1,i ]
```

### Etude approfondie du modèle de forêt aléatoire :

La fonction plot.survival permet d'avoir une synthèse graphique de résultats :

```{r}
plot.survival(v.obj, subset = 1)
```

#### Performances du modèle RSF :

Commentaire et explication :

-   Le modèle de forêt aléatoire de survie est plus performant que le modèle de Cox simple (7 variables explicatives) et le modèle de Cox complet (toutes les variables explicatives).

```{r}
## obtain Brier score using KM and RSF censoring distribution estimators
bs.km <- get.brier.survival(v.obj, cens.model = "km")$brier.score
bs.rsf <- get.brier.survival(v.obj, cens.model = "rfsrc")$brier.score

## plot the brier score : Evolution de l'erreur de prédiction
plot(bs.km, type = "s", col = 2)
lines(bs.rsf, type ="s", col = 4)
legend("topleft", legend = c("cens.model = Kaplan Meier", 
                             "cens.model = Random forest"), fill = c(2,4))

```

### Prise en compte de l'importance des variables :

Importance des variables (VIMP) :

Plusieurs méthodes sont possibles pour l'importance d'une variable $x$ :

-   importance = "permute" : calcul d'importance par permutation aléatoire des valeurs de $x$ observées sur les exemples OOB.

-   importance = "random" : calcul d'importance par choix aléatoire gauche/droite lorsqu'une coupure se fait avec la variable $x$.

-   importance = "anti" : calcul d'importance en choisissant le choix opposé à celui proposé.

```{r results='hide'}
imp1 = subsample(v.obj, importance = "anti")
plot(imp1)
```

```{r results='hide'}
imp2 = subsample(v.obj, importance = "permute")
plot(imp2)
```

```{r results='hide'}
imp3 = subsample(v.obj, importance = "random")
plot(imp3)
```

#### Estimation sur les variables ayant le plus d'importance :

```{r}
library(randomForestSRC)
v.obj <- rfsrc(
  Surv(days, status) ~ age + edema + bili + albumin +
    sgot + prothrombin + stage,
  data = x,
  ntree = 100
)

## plot tree number 3
plot(get.tree(v.obj, 3))

get.cindex(
  time = x$days,
  censoring = x$status,
  predicted = v.obj$predicted.oob
)
```

#### Affichage grahique de la fonction de survie sur le modèle simplifié :

```{r}
plot(
  v.obj$time.interest,
  t(v.obj$survival.oob[1,]),
  xlab = "Mois",
  ylab = "Probabilté de survie",
  type = "l",
  main = "Comparaison des modèles de survie",
  lty = 1,
  col = palette_couleur[1],
  lwd = 2
)
lines(tcox1$time, tcox1$surv, col = palette_couleur[2], lwd = 2)
legend("topright",
       legend = c("RF simplifié", "Cox 7 var"),
       fill = palette_couleur[1:2], lwd = 1)


# Probabilité de survie au 400e jour pour l'individu 1 :
i=which(v.obj$time.interest==400)
#i
v.obj$survival.oob[1,i ]
```


```{r echo=FALSE}
rm(list = setdiff(ls(), "palette_couleur")) # Nettoyage de l'environnement
```

# Autres exercices :

## Exercice sur la modélisation de Lee-Carter

### Importation des données :

Importation des données de mortalité pour la France de 1816 à 2021.

Référence du site [HMD](http://www.mortality.org).

```{r}
# Décès
de = read.csv("DATA/DeathsFrance2024.csv", header = TRUE, sep = ";")
#str(de)
# remarque : la classe d'âge "110" est en réalité "110 et plus".

# Expositions
ex = read.csv("DATA/ExposuresFrance2024.csv", header = TRUE, sep = ";")
#str(ex)

# Force de mortalité : \mu_{x,t}= m_{x,t} (m_{x,t} taux de mortalité)
age = 0:110
annee = 1816:2021
mu = de[, 3:5] / ex[, 3:5]
mut = matrix(mu[, 3], length(age), length(annee))
persp(
  age[1:100],
  annee,
  log(mut[1:100, ]),
  theta = -30,
  col = "light green",
  shade = TRUE
)

```

### Modélisation de Lee-Carter :

```{r}
library(forecast)
library(demography)

# Calibrage Lee-Carter avec l'ensemble de données
annee = unique(de$Year)
nc = length(annee)
age = unique(de$Age)
nl = length(age)

muf = matrix(de$Female / ex$Female, nl, nc)  # Données Femmes
muh = matrix(de$Male / ex$Male, nl, nc)  # Données Hommes

popf = matrix(ex$Female, nl, nc)
poph = matrix(ex$Male, nl, nc)

Baseh = demogdata(
  data = muh,
  pop = poph,
  ages = age,
  years = annee,
  type = "mortality",
  label = 'France',
  name = 'Hommes',
  lambda = 1
)

Basef = demogdata(
  data = muf,
  pop = popf,
  ages = age,
  years = annee,
  type = "mortality",
  label = 'France',
  name = 'Femmes',
  lambda = 1
)

lch = lca(Baseh)

# Estimation de alpha_x
plot(
  lch$age,
  lch$ax,
  main = "Estimation de la valeur moyenne alpha_x",
  col = palette_couleur[1],
  xlab = "Age",
  ylab = "Valeur moyenne", 
  type = 'l', 
  lwd = 2
)

# Estimation de beta_x
plot(
  lch$age,
  lch$bx,
  main = "Estimation de la sensibilité beta_x",
  col = palette_couleur[1],
  xlab = "Age",
  ylab = "Sensibilité", 
  type = 'l',
  lwd = 2
)

# Estimation des k_t
kt = lch$kt
plot(
  annee,
  kt,
  main = "Estimation des k_t",
  col = palette_couleur[1],
  xlab = "Année",
  ylab = "k_t", 
  type = 'l',
  lwd = 2
)

```

### Projection des k_t méthode de Lee & Carter (1992) :

On fait l'hypothèse que les $k_t$ sont déterminés par la relation suivante :

$$
k_t = k_{t-1} + d + \epsilon_t
$$

avec :

-   $k_t$ : les valeurs de $k$ à l'instant $t$.
-   $k_{t-1}$ : les valeurs de $k$ à l'instant $t-1$.
-   $d$ : une constante.
-   $epsilon_t$ : un bruit blanc.

```{r}
plot(lch) # Affichage des résultats

# Projection des k_t à l'aide du modèle initial :
proj = forecast(lch, h = 20)
plot(proj, plot.type = "component")
par(mfrow = c(1, 1))

# Ou bien un auto-arima pour modéliser et projeter les k_t :
ar = auto.arima(kt)
plot(forecast(ar, h = 10))

# Modèle sans ajustement des Kt : 
lch_sans = lca(Baseh, adjust = "none")

```

#### Comparaison avec et sans ajustement des $k_t$ :

```{r}
plot(
  lch$year,
  lch$kt,
  col = palette_couleur[1],
  type = 'l',
  main = "Effet ajustement sur les k_t",
  xlab = "Année",
  ylab = "k_t",
  lwd = 2
)
lines(lch_sans$year, lch_sans$kt, col = palette_couleur[2], lwd = 2)
legend(
  1840,-50,
  legend = c("avec ajust.", "sans ajust."),
  col = palette_couleur[1:2],
  lty = 1,
  cex = 0.8
)

```


```{r echo=FALSE}
rm(list = setdiff(ls(), "palette_couleur")) # Nettoyage de l'environnement
```

## Exercice 2 : La modélisation de log-Poisson

Human Mortality Database [HMD](http://www.mortality.org)

### Importation des données :

```{r}
# Décès
de = read.csv("DATA/DeathsFrance2024.csv", header = TRUE, sep = ";")
# remarque : la classe d'âge "110" est en réalité "110 et plus".

# Expositions
ex = read.csv("DATA/ExposuresFrance2024.csv", header = TRUE, sep = ";")
#str(ex)

```

### Modélisation log-Poisson :

On peut calibrer ce modèle avec la fonction gnm (generalized nonlinear model).

Le modèle de Lee-Carter suppose que les résidus sont homoscédastiques c'est à dire que l'aléa de nuisance $\epsilon_{x,t}$ est constant dans le temps et par âge.
Le modèle de Log-Poisson permet de relacher cette hypothèse en considérant que la variance des taux de décès augmente pour les âges élevés.

On va modéliser le nombre de décès $D_{x,t}$ par une loi de Poisson conditionnelle à l'exposition $L_{x,t}$ et à un terme multiplicatif $\mu_{x,t}$ qui dépend de l'âge et de l'année.
Ainsi on obtient que $\mu_{x,t} = \exp(\alpha_x + \beta_x k_t)$, tel que $D_{x,t} \sim \mathcal{P}(\mu_{x,t} \times L_{x,t})$.

On se rapproche d'un modèle de Lee-Carter pour qui la fonction de mortalité est donnée par $\mu_{x,t} = \exp(\alpha_x + \beta_x k_t)$ mais on considère une loi de Poisson pour les décès et non pas une loi normale centrée réduite.

Afin d'utiliser la fonction gnm, utilisée pour les modélisations non-linéaire généralisées on doit adapter les données.

$\mu_{x,t} = \exp(\alpha_x + \beta_x k_t) = \sum_{a = x_{\text{min}}}^{x_{\text{max}}} \alpha_{\alpha} \textbf{1}_{[\alpha]}(x) + \sum_{a = x_{\text{min}}}^{x_{\text{max}}} \sum_{b = t_{\text{min}}}^{t_{\text{max}}} \beta_{\alpha} k_{b} \textbf{1}_{[\alpha]}(x) \textbf{1}_{[b]}(t)$

Pour obtenir cette équation dans R on applique des facteurs aux variables afin de récréer les indicatrices dans la fonction gnn.

#### Modélisation et adaptation des donnéés :

```{r}
library(gnm)

# Sélection des données : 
ind = which((de$Age > 44) & (de$Age < 100) &
              (de$Year > 1949) & (de$Year < 2013))
annee = 1950:2012
nc = length(annee)
age = 45:99
nl = length(age)

D = de$Male[ind]
E = ex$Male[ind]
x = as.factor(ex$Age[ind])
t = as.factor(ex$Year[ind])

regp <-
  gnm(D ~ 0 + x + Mult(x, t),
      offset = log(E),
      family = poisson(link = "log"))

nomvar = names(regp$coefficients)

set.seed(123)
#Simulation aléatoire de 10 variables explicatives pour visualiser :
nomvar[sample(1:length(nomvar), 10)]

# Explication de la fonction Mult(x,t) :
# Elle permet de modéliser l'interaction entre l'âge et l'année.

```

#### Estimation des coefficients :

```{r}
plot(
  45:99,
  regp$coefficients[1:55],
  main = "coefficients alpha_x",
  xlab =
    "Ages",
  type = 'l',
  col = palette_couleur[1],
  lwd = 2
)

plot(
  45:99,
  regp$coefficients[56:110],
  main = "coefficients beta_x",
  xlab = "Ages",
  type = 'l',
  col = palette_couleur[2],
  lwd = 2
)

plot(
  1950:2012,
  regp$coefficients[111:173],
  main = "coefficients k_t",
  xlab = "Années",
  type = 'l',
  col = palette_couleur[3],
  lwd = 2
)

```

Le coefficient $\alpha_x$ est la valeur moyenne de la mortalité pour l'âge $x$.

Le coefficient $\beta_x$ est la sensibilité de la mortalité à l'âge $x$.

Le coefficient $k_t$ est l'effet temporel.

#### Normalisation des coefficients :

```{r}
alpha = regp$coefficients[1:55]
k = regp$coefficients[111:173]
beta = regp$coefficients[56:110]

# On "normalise" les paramètres comme pour Lee-Carter :
sb = sum(beta)
beta = beta / sb
mk = mean(k)
k = (k - mk) * sb
alpha = alpha + beta * mk


plot(
  45:99,
  alpha,
  main = "coefficients alpha_x normalisé",
  xlab =
    "Ages",
  type = 'l',
  col = palette_couleur[1],
  lwd = 2
)

plot(
  45:99,
  beta,
  main = "coefficients beta_x normalisé",
  xlab = "Ages",
  type = 'l',
  col = palette_couleur[2],
  lwd = 2
)

plot(
  1950:2012,
  k,
  main = "coefficients k_t normalisé",
  xlab = "Années",
  type = 'l',
  col = palette_couleur[3],
  lwd = 2
)
```

### Comparaison avec Lee-Carter classique :

La fonction R du modèle de Lee-Carter calcule le logarithme de la mortalité : $$ \mu_{x,t} = \log(q_{x,t}) $$

On utilise alors la relation ci-dessous pour faire le lien entre l'estimation de Lee-Carter et le modèle de Poisson :

$logit(q_{x,t}) = ln(\frac{q_{x,t}}{1-q_{x,t}}) \approx ln(\mu_{x,t})$

$logit(q_{x,t}) = \alpha_x + \beta_x k_t + \epsilon_{x,t}$

```{r}
# calcul des log(mu_{x,t})
logmu = matrix(NA, nrow = 55, ncol = 63)
for (i  in 1:55)
{
  for (j in 1:63)
  {
    logmu[i, j] = alpha[i] + beta[i] * k[j]
  }
}
```

#### Modélisation de Lee-Carter classique :

```{r}
# Comparaison avec Lee Carter classique
library(demography)
muh = matrix(de$Male[ind] / ex$Male[ind], nl, nc)
poph = matrix(ex$Male[ind], nl, nc)

Baseh = demogdata(
  data = muh, # taux de mortalité
  pop = poph, # population
  ages = age, # âges
  years = annee, # années
  type = "mortality", # type de données
  label = 'France', # label
  name = 'Hommes', # genre 
  lambda = 1 
)
lch = lca(Baseh)
plot(lch)
```

#### Comparaison des paramètres Log Poisson / Lee Carter :

```{r}
# Coefficients alpha_x : 
plot(
  45:99,
  alpha,
  main = "Comparaison des coefficients alpha_x",
  xlab = "Ages",
  type = 'l',
  col = palette_couleur[1],
  lwd = 2
)
lines(45:99, lch$ax, col = palette_couleur[2], lwd = 2)
legend(
  50,
  -1,
  legend = c("Log Poisson", "Lee Carter"),
  col = c(palette_couleur[1], palette_couleur[2]),
  lty = 1,
  cex = 0.8, 
  lwd = 2
)

# Coefficients beta_x :
plot(
  45:99,
  beta,
  main = "Comparaison des coefficients beta_x",
  xlab = "Ages",
  type = 'l',
  col = palette_couleur[1],
  lwd = 2
)
lines(45:99, lch$bx, col = palette_couleur[2], lwd = 2)
legend(
  50,
  0.01,
  legend = c("Log Poisson", "Lee Carter"),
  col = c(palette_couleur[1], palette_couleur[2]),
  lty = 1,
  cex = 0.8, 
  lwd = 2
)

# Coefficients k_t :
plot(
  1950:2012,
  k,
  main = "Comparaison des coefficients k_t",
  xlab = "Années",
  type = 'l',
  col = palette_couleur[1],
  lwd = 2
)
lines(1950:2012, lch$kt, col = palette_couleur[2], lwd = 2)
legend(
  1955,
  -10,
  legend = c("Log Poisson", "Lee Carter"),
  col = c(palette_couleur[1], palette_couleur[2]),
  lty = 1,
  cex = 0.8,
  lwd = 2
)

```

#### Etude de l'erreur de prédiction des modèles :

```{r}

# Prédiction de Lee-Carter 
predh=lch$fitted$y # c'est log(mu_{x,t}) qui est prédit

# Comparaison Lee-Carter / données réelles
rmseh=sqrt(sum((log(muh)-(predh))^2)/(nl-1)/nc)

# Comparaison Log Poisson / données réelles
rmseh1=sqrt(sum((logmu-(log(muh)))^2)/(nl-1)/nc)

# Comparaison Log Poisson / Lee-Carter
rmseh2=sqrt(sum((logmu-predh)^2)/(nl-1)/nc)

# Tableau comparatif des erreurs : 
dt = t(round(data.frame("Lee Carter vs reel" = rmseh,
           "Log Poisson vs reel" =   rmseh1,
           "Log Poisson vs  Lee Carter" = rmseh2),4))
colnames(dt) = c("Erreur quadratique moyenne")
dt

```

##### Comparaison graphique des prédictions :

-   On compare graphiquement $\mu_{x,t}$ prédit par le modèle de Lee-Carter et le modèle de Log-Poisson pour l'année 2012.

```{r}
plot(
  45:99,
  exp(logmu[, 63]),
  main = "mu_{x,2012}",
  type = 'l',
  xlab = "Ages",
  col = palette_couleur[1],
  lwd = 2
)
lines(45:99, exp(predh[, 63]), col = palette_couleur[2], lwd = 2)
legend(
  50,
  0.3,
  legend = c("Log Poisson", "Lee Carter"),
  col = c(palette_couleur[1], palette_couleur[2]),
  lty = 1,
  cex = 0.8,
  lwd = 2
)

```

-   Comparaison des log(mu\_{x,2012}) prédits par les deux modèles et les données observées :

```{r}
plot(
  45:99,
  logmu[, 63],
  main = "log(mu_{x,2012})",
  type = 'l',
  xlab = "Ages",
  col = palette_couleur[1],
  lwd = 2
)
lines(45:99, predh[, 63], col = palette_couleur[2], lwd = 2)
lines(45:99, log(muh[, 63]), col = palette_couleur[3], lwd = 2)
legend(
  50,
  -1,
  legend = c("Log Poisson", "Lee Carter", "obs."),
  col = c(palette_couleur[1], palette_couleur[2], palette_couleur[3]),
  lty = 1,
  cex = 0.8,
  lwd = 2
)
```

```{r echo=FALSE}
rm(list = setdiff(ls(), "palette_couleur")) # Nettoyage de l'environnement
```
